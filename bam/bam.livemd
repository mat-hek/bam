# Project bam bam

```elixir
Logger.configure(level: :info)

Mix.install([
  :evision,
  :membrane_sdk,
  {:membrane_webrtc_plugin, "~> 0.19.0"},
  {:ex_sdp, "~> 0.15.0", override: true},
  {:utils, path: "#{__DIR__}/utils"},
  :kino
])
```

## Get media

```elixir
import Membrane.ChildrenSpec

p = Membrane.RCPipeline.start_link!()

Membrane.RCPipeline.exec_actions(p,
  spec:
    child(Membrane.CameraCapture)
    |> child(%Membrane.FFmpeg.SWScale.PixelFormatConverter{format: :I420})
    |> child(Membrane.SDL.Player)
)
```

```elixir
Membrane.Pipeline.terminate(p)
```

## Detect hand movement

```elixir
path = "#{__DIR__}/../models"

network =
  Evision.DNN.readNetFromDarknet("#{path}/cross-hands.cfg",
    darknetModel: "#{path}/cross-hands.weights"
  )

Evision.DNN.Net.setPreferableTarget(network, Evision.Constant.cv_DNN_TARGET_OPENCL())
Evision.DNN.Net.setPreferableBackend(network, Evision.Constant.cv_DNN_BACKEND_OPENCV())
output_layers = Evision.DNN.Net.getUnconnectedOutLayersNames(network)

model = %{network: network, output_layers: output_layers, input_size: {416, 416}}
```

```elixir
defmodule BamBam do
  use Membrane.Filter

  def_input_pad(:input, accepted_format: Membrane.RawVideo)
  def_output_pad(:output, accepted_format: Membrane.RawAudio)

  def_options(model: [])

  @bam %Membrane.Buffer{payload: File.read!("#{__DIR__}/bam.pcm")}
  @clap %Membrane.Buffer{payload: File.read!("#{__DIR__}/clap.pcm")}
  @out_format %Membrane.RawAudio{sample_rate: 48_000, channels: 2, sample_format: :s16le}

  @impl true
  def handle_init(_ctx, opts) do
    frame = Kino.Frame.new()
    Kino.render(frame)
    {[], %{processing: false, in_format: nil, frame: frame, model: opts.model, min_y: 1}}
  end

  @impl true
  def handle_stream_format(:input, in_format, _ctx, state) do
    {[stream_format: {:output, @out_format}], %{state | in_format: in_format}}
  end

  @impl true
  def handle_buffer(:input, buffer, _ctx, state) do
    element = self()

    unless state.processing do
      Task.start_link(fn ->
        inference = infer(buffer.payload, state.in_format, state.model)
        send(element, inference)
      end)
    end

    {[], %{state | processing: true}}
  end

  @impl true
  def handle_info(inf, _ctx, state) do
    state = %{state | processing: false}

    if inf.score >= 0.5, do: Kino.Frame.render(state.frame, inf)

    cond do
      inf.score < 0.5 ->
        {[], state}

      inf.y < state.min_y ->
        {[], %{state | min_y: inf.y}}

      inf.y - state.min_y > 0.1 ->
        buffer =
          if inf.x < 0.5 do
            IO.write("CLAP ")
            @clap
          else
            IO.write("BAM ")
            @bam
          end

        {[buffer: {:output, buffer}], %{state | min_y: 1}}

      true ->
        {[], state}
    end
  end

  defp infer(image, format, model) do
    img = Evision.Mat.from_binary(image, {:u, 8}, format.height, format.width, 3)

    blob =
      Evision.DNN.blobFromImage(img, scalefactor: 1.0 / 255.0, size: model.input_size)

    Evision.DNN.Net.setInput(model.network, blob)
    outputs = Evision.DNN.Net.forwardAndRetrieve(model.network, model.output_layers)

    outputs
    |> List.flatten()
    |> Enum.map(&Evision.Mat.to_nx/1)
    |> Enum.flat_map(&Nx.to_list/1)
    |> Enum.map(fn [x, y, _w, h | scores] ->
      %{x: x - h / 2, y: y, score: Enum.max(scores)}
    end)
    |> Enum.max_by(& &1.score)
  end
end
```

<!-- livebook:{"branch_parent_index":1} -->

## BamBam

```elixir
import Membrane.ChildrenSpec

p = Membrane.RCPipeline.start_link!()

Membrane.RCPipeline.exec_actions(p,
  spec:
    child(Membrane.CameraCapture)
    |> child(%Membrane.FFmpeg.SWScale.PixelFormatConverter{format: :RGB})
    |> child(%BamBam{model: model})
    |> child(Membrane.PortAudio.Sink)
)
```

```elixir
Membrane.RCPipeline.terminate(p)
```

<!-- livebook:{"branch_parent_index":1} -->

## WebRTC

```elixir
ip = {192, 168, 83, 200}
```

```elixir
import Membrane.ChildrenSpec

p = Membrane.RCPipeline.start_link!()

Membrane.RCPipeline.exec_actions(p,
  spec:
    child(%Membrane.WebRTC.Source{
      signaling: {:websocket, ip: ip, port: 8829},
      video_codec: :h264
    })
    |> via_out(:output, options: [kind: :video])
    |> child(Membrane.H264.Parser)
    |> child(Membrane.H264.FFmpeg.Decoder)
    |> child(%Membrane.FFmpeg.SWScale.PixelFormatConverter{format: :RGB})
    |> child(%BamBam{model: model})
    |> child(Utils.SilenceFiller)
    |> child(Membrane.Opus.Encoder)
    |> via_in(:input, options: [kind: :audio])
    |> child(%Membrane.WebRTC.Sink{signaling: {:websocket, ip: ip, port: 8830}})
)
```

```elixir
Membrane.RCPipeline.terminate(p)
```
