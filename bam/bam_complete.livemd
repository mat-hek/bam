# Project bam bam - complete

```elixir
Logger.configure(level: :info)

Mix.install([
  :evision,
  :membrane_sdk,
  {:membrane_webrtc_plugin, "~> 0.19.0"},
  {:ex_sdp, "~> 0.15.0", override: true},
  {:utils, path: "#{__DIR__}/utils"},
  :kino
])
```

## Project bam bam

<!-- livebook:{"branch_parent_index":0} -->

## Get media

Things to do:

* Receive video over WebRTC
* Parse the video
* Decode the video
* Convert the video from YUV to RGB

```elixir
import Membrane.ChildrenSpec

p = Membrane.RCPipeline.start_link!()

Membrane.RCPipeline.exec_actions(p,
  spec:
    child(%Membrane.WebRTC.Source{signaling: {:websocket, port: 8829}, video_codec: :h264})
    |> via_out(:output, options: [kind: :video])
    |> child(Membrane.H264.Parser)
    |> child(Membrane.H264.FFmpeg.Decoder)
    |> child(%Membrane.FFmpeg.SWScale.PixelFormatConverter{format: :RGB})
    |> child(%Membrane.Debug.Sink{handle_stream_format: &IO.inspect/1})
)
```

```elixir
Membrane.Pipeline.terminate(p)
```

<!-- livebook:{"branch_parent_index":0} -->

## Detect hand movement

* Models prepared by Florian Bruggisser, source: https://github.com/cansik/yolo-hand-detection
* Using [Evision](https://github.com/cocoa-xu/evision) to do the inference

```elixir
defmodule BamDetector do
  def load_model() do
    path = "#{__DIR__}/../models"

    network =
      Evision.DNN.readNetFromDarknet("#{path}/cross-hands-tiny.cfg",
        darknetModel: "#{path}/cross-hands-tiny.weights"
      )

    output_layers = Evision.DNN.Net.getUnconnectedOutLayersNames(network)

    %{network: network, output_layers: output_layers}
  end

  def infer(image, format, model) do
    img = Evision.Mat.from_binary(image, {:u, 8}, format.height, format.width, 3)

    blob =
      Evision.DNN.blobFromImage(img, scalefactor: 1.0 / 255.0, size: {416, 416})

    Evision.DNN.Net.setInput(model.network, blob)
    outputs = Evision.DNN.Net.forwardAndRetrieve(model.network, model.output_layers)

    outputs
    |> List.flatten()
    |> Enum.map(&Evision.Mat.to_nx/1)
    |> Enum.flat_map(&Nx.to_list/1)
    |> Enum.map(fn [x, y, _w, h | scores] ->
      %{x: x, y: y - h / 2, score: Enum.max(scores)}
    end)
    |> Enum.max_by(& &1.score)
  end

  def init_detector() do
    %{min_y: 1}
  end

  def detect(inference, detector_state) do
    cond do
      inference.score < 0.5 -> {false, detector_state}
      inference.y < detector_state.min_y -> {false, %{detector_state | min_y: inference.y}}
      inference.y - detector_state.min_y > 0.2 -> {true, init_detector()}
      true -> {false, detector_state}
    end
  end
end
```

```elixir
defmodule BamSound do
  def format() do
    %Membrane.RawAudio{sample_rate: 48_000, channels: 2, sample_format: :s16le}
  end

  def bam() do
    File.read!("#{__DIR__}/bam.pcm")
  end
end
```

```elixir
defmodule BamBam do
  use Membrane.Filter

  def_input_pad(:input, accepted_format: Membrane.RawVideo)
  def_output_pad(:output, accepted_format: Membrane.RawAudio)

  @impl true
  def handle_init(_ctx, _opts) do
    state = %{
      input_format: nil,
      model: BamDetector.load_model(),
      detector_state: BamDetector.init_detector(),
      bam: BamSound.bam(),
      processing: false
    }

    {[], state}
  end

  @impl true
  def handle_stream_format(:input, format, _ctx, state) do
    {[stream_format: {:output, BamSound.format()}], %{state | input_format: format}}
  end

  @impl true
  def handle_buffer(:input, buffer, _ctx, state) do
    if state.processing == false do
      element = self()

      Task.start_link(fn ->
        inference = BamDetector.infer(buffer.payload, state.input_format, state.model)
        send(element, inference)
      end)
    end

    {[], %{state | processing: true}}
  end

  @impl true
  def handle_info(inference, _ctx, state) do
    {is_bam, detector_state} = BamDetector.detect(inference, state.detector_state)
    state = %{state | processing: false, detector_state: detector_state}

    if is_bam do
      buffer = %Membrane.Buffer{payload: state.bam}
      {[buffer: {:output, buffer}], state}
    else
      {[], state}
    end
  end
end
```

```elixir
import Membrane.ChildrenSpec

p = Membrane.RCPipeline.start_link!()

Membrane.RCPipeline.exec_actions(p,
  spec:
    child(%Membrane.WebRTC.Source{signaling: {:websocket, port: 8829}, video_codec: :h264})
    |> via_out(:output, options: [kind: :video])
    |> child(Membrane.H264.Parser)
    |> child(Membrane.H264.FFmpeg.Decoder)
    |> child(%Membrane.FFmpeg.SWScale.PixelFormatConverter{format: :RGB})
    |> child(%Membrane.Debug.Filter{handle_stream_format: &IO.inspect/1})
    |> child(BamBam)
    |> child(Utils.SilenceFiller)
    |> child(Membrane.Opus.Encoder)
    |> via_in(:input, options: [kind: :audio])
    |> child(%Membrane.WebRTC.Sink{signaling: {:websocket, port: 8830}})
)
```

```elixir
Membrane.Pipeline.terminate(p)
```